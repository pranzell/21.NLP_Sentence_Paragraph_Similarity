{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence-Paragraph Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Importing Various packages ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import math\n",
    "import scipy.stats as scipy\n",
    "\n",
    "\n",
    "# --- NLTK PACKAGE ---\n",
    "import nltk\n",
    "# Tokenizers\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, PunktSentenceTokenizer, RegexpTokenizer\n",
    "# Lemmatizing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords, state_union\n",
    "\n",
    "\n",
    "# --- GENSIM PACKAGE ---\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, doc2vec, Doc2Vec\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>questions</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>[[What is the Grotto at Notre Dame?, To whom d...</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ ...</td>\n",
       "      <td>[[In what city and state did Beyonce  grow up?...</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Montana i/mɒnˈtænə/ is a state in the Western...</td>\n",
       "      <td>[[What is its rank in popularion?, What is the...</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The phrase \"in whole or in part\" has been sub...</td>\n",
       "      <td>[[Which phrase is especially contentious withi...</td>\n",
       "      <td>Genocide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The emergence of resistance of bacteria to an...</td>\n",
       "      <td>[[What is the purpose of antibiotic treatment?...</td>\n",
       "      <td>Antibiotics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  [Architecturally, the school has a Catholic ch...   \n",
       "1  [Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ ...   \n",
       "2  [Montana i/mɒnˈtænə/ is a state in the Western...   \n",
       "3  [The phrase \"in whole or in part\" has been sub...   \n",
       "4  [The emergence of resistance of bacteria to an...   \n",
       "\n",
       "                                           questions                     title  \n",
       "0  [[What is the Grotto at Notre Dame?, To whom d...  University_of_Notre_Dame  \n",
       "1  [[In what city and state did Beyonce  grow up?...                   Beyoncé  \n",
       "2  [[What is its rank in popularion?, What is the...                   Montana  \n",
       "3  [[Which phrase is especially contentious withi...                  Genocide  \n",
       "4  [[What is the purpose of antibiotic treatment?...               Antibiotics  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_json('squad_train_doc.json')\n",
    "data_train.rename(columns={'passages': 'documents'}, inplace=True)\n",
    "\n",
    "def get_compact_dataframe():\n",
    "    context_list = []\n",
    "    question_list = []\n",
    "    for doc in data_train.documents:\n",
    "        context_list.append(get_each_context_each_questionSet(doc)[0])\n",
    "        question_list.append(get_each_context_each_questionSet(doc)[1])\n",
    "    return context_list, question_list\n",
    "\n",
    "def get_each_context_each_questionSet(document):\n",
    "    each_doc_context_list = [document[i]['context'] for i in range(len(document))]\n",
    "    each_doc_question_list = [document[i]['questions'] for i in range(len(document))]\n",
    "    return  each_doc_context_list, each_doc_question_list\n",
    "\n",
    "context_list, question_list = get_compact_dataframe()[0], get_compact_dataframe()[1]\n",
    "dataframe = pd.DataFrame({'title':data_train.title, 'context':context_list, 'questions': question_list})\n",
    "list_all_context_per_doc = [' '.join(context_list[i]) for i in range(len(context_list))]\n",
    "list_all_questions_per_doc = [sum(question_list[i],[]) for i in range(len(question_list))]\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = 'What is Grotto at Norte Dame?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Storing document[i] in document\n",
    "document = list_all_context_per_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading WMD Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WMD_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1 : BM25 Filter  +  WMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunking(document, step):\n",
    "    sentences = sent_tokenize(document)\n",
    "    chunks = []\n",
    "    chunks = [sentences[i:i+step] for i in range(0, len(sentences), step)]\n",
    "    #chunks = [sentences[i:i+10] for i in range(0, len(sentences)-10)]\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chunks = chunking(document, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(chunks):\n",
    "    chunked_words = [word_tokenize(' '.join(chunk)) for chunk in chunks]\n",
    "    chunked_words_without_stopwords = []\n",
    "    for chunk in chunked_words:\n",
    "        chunked_words_without_stopwords.append([word for word in chunk if word not in stop_words])\n",
    "    return chunked_words_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_chunked_words = remove_stopwords(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BM25_Paragraph_Model = gensim.summarization.bm25.BM25(tokenized_chunked_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BM25(query):    \n",
    "    scores = BM25_Paragraph_Model.get_scores(query.split() ,1) \n",
    "    chunk_names = [i for i in range(len(chunks))]\n",
    "    BM25_dataframe = pd.DataFrame({'Chunk':chunk_names, 'Score':scores}).sort_values(by=['Score'],ascending=False)\n",
    "    BM25_dataframe['Rank'] = [i for i in range(1, len(chunks)+1)]\n",
    "\n",
    "    return BM25_dataframe.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Score</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>4.951295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.133145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3.133145</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.133145</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3.133145</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Chunk     Score  Rank\n",
       "0     36     36  4.951295     1\n",
       "1      0      0  3.133145     2\n",
       "2     12     12  3.133145     3\n",
       "3      2      2  3.133145     4\n",
       "4     20     20  3.133145     5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM25_Dataframe = BM25(query)\n",
    "BM25_Dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chunk_selector(BM25_Dataframe, threshold):\n",
    "    highest_score = BM25_Dataframe.Score[0]\n",
    "    selected_chunk_numbers = []\n",
    "    selected_chunk_numbers.append(BM25_Dataframe.Chunk[0])\n",
    "    if BM25_Dataframe.Score[0] - BM25_Dataframe.Score[1] < threshold:\n",
    "        for index in range(1, len(BM25_Dataframe.Score)):    \n",
    "            if BM25_Dataframe.Score[0] - BM25_Dataframe.Score[index] < threshold:\n",
    "                selected_chunk_numbers.append(BM25_Dataframe.Chunk[index])\n",
    "    \n",
    "    return selected_chunk_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_chunk_numbers = chunk_selector(BM25_Dataframe, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WMD_in_chunks(query, chunks, selected_chunk_numbers):\n",
    "\n",
    "    sent1 = word_tokenize(query)\n",
    "    \n",
    "    list_sentences, list_distances, list_chunkNumber, list_sentence_index = [], [], [], []  \n",
    "    for index in selected_chunk_numbers:\n",
    "        for each_sentence_index, each_sentence in zip(range(len(chunks[index])), chunks[index]):\n",
    "            sent2 = word_tokenize(each_sentence)\n",
    "            similarity_distance = WMD_model.wmdistance(sent1, sent2)\n",
    "            list_sentences.append(each_sentence)\n",
    "            list_distances.append(similarity_distance)\n",
    "            list_sentence_index.append(each_sentence_index)\n",
    "            list_chunkNumber.append(index)\n",
    "    WMD_Dataframe = pd.DataFrame({'Sentence': list_sentences, 'WMD_Score': list_distances, 'Chunk': list_chunkNumber, 'Sentence_Index': list_sentence_index})\n",
    "\n",
    "    return WMD_Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Chunk</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>WMD_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>184</td>\n",
       "      <td>35</td>\n",
       "      <td>The \"Notre Dame Victory March\" is the fight so...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.554218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160</td>\n",
       "      <td>33</td>\n",
       "      <td>Kelly's record in midway through his sixth sea...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.628065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>19</td>\n",
       "      <td>Notre Dame's most recent[when?]</td>\n",
       "      <td>2</td>\n",
       "      <td>2.707056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>20</td>\n",
       "      <td>The Grotto of Our Lady of Lourdes, which was b...</td>\n",
       "      <td>7</td>\n",
       "      <td>2.718668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140</td>\n",
       "      <td>31</td>\n",
       "      <td>The Notre Dame Leprechaun is the mascot of the...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.738287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>What though the odds be great or small, old No...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.752606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Immediately behind the basilica is the Grotto,...</td>\n",
       "      <td>4</td>\n",
       "      <td>2.811086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>178</td>\n",
       "      <td>34</td>\n",
       "      <td>The team is coached by Mike Brey, who, as of t...</td>\n",
       "      <td>8</td>\n",
       "      <td>2.886310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>Notre Dame alumni work in various fields.</td>\n",
       "      <td>8</td>\n",
       "      <td>2.886595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>170</td>\n",
       "      <td>34</td>\n",
       "      <td>Later that day, the trumpet section will play ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.888879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Chunk                                           Sentence  \\\n",
       "0    184     35  The \"Notre Dame Victory March\" is the fight so...   \n",
       "1    160     33  Kelly's record in midway through his sixth sea...   \n",
       "2    202     19                    Notre Dame's most recent[when?]   \n",
       "3     47     20  The Grotto of Our Lady of Lourdes, which was b...   \n",
       "4    140     31  The Notre Dame Leprechaun is the mascot of the...   \n",
       "5      1     36  What though the odds be great or small, old No...   \n",
       "6     14      0  Immediately behind the basilica is the Grotto,...   \n",
       "7    178     34  The team is coached by Mike Brey, who, as of t...   \n",
       "8      8     36          Notre Dame alumni work in various fields.   \n",
       "9    170     34  Later that day, the trumpet section will play ...   \n",
       "\n",
       "   Sentence_Index  WMD_Score  \n",
       "0               4   2.554218  \n",
       "1               0   2.628065  \n",
       "2               2   2.707056  \n",
       "3               7   2.718668  \n",
       "4               0   2.738287  \n",
       "5               1   2.752606  \n",
       "6               4   2.811086  \n",
       "7               8   2.886310  \n",
       "8               8   2.886595  \n",
       "9               0   2.888879  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WMD_Dataframe = WMD_in_chunks(query, chunks, selected_chunk_numbers).sort_values(by=['WMD_Score'], ascending=True).reset_index()\n",
    "WMD_Dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paragraph1(chunks, WMD_Dataframe_Top):\n",
    "    \n",
    "    chunk_index = WMD_Dataframe_Top.Chunk[0]\n",
    "    sentence_index = WMD_Dataframe_Top.Sentence_Index[0]\n",
    "    if sentence_index >=3 and sentence_index <=6:\n",
    "        paragraph = chunks[chunk_index][sentence_index-3:sentence_index+5]\n",
    "    elif sentence_index <3:\n",
    "        if chunk_index!=0:\n",
    "            previous_chunk = chunks[chunk_index-1][-3:]\n",
    "            paragraph = previous_chunk[sentence_index:] +  chunks[chunk_index][:sentence_index+5]        \n",
    "        else:\n",
    "            paragraph = chunks[chunk_index][0:8]             \n",
    "    else:\n",
    "        if chunk_index != len(chunks)-1 :\n",
    "            after_chunk = chunks[chunk_index+1][0:4]\n",
    "            paragraph = chunks[chunk_index][sentence_index-3:] + after_chunk[0:4 - (9 -sentence_index)]\n",
    "        else:\n",
    "            paragraph = chunks[chunk_index][-8:]        \n",
    "\n",
    "    return ' '.join(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "para =[]\n",
    "\n",
    "for i in range(0,11):\n",
    "    para.append(paragraph(chunks, WMD_Dataframe[i:i+1].reset_index()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Approach 2: Only WMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>WMD_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>program also exists.</td>\n",
       "      <td>40</td>\n",
       "      <td>3.593895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1,400 of the 3,577 (39.1%) were admitted under...</td>\n",
       "      <td>59</td>\n",
       "      <td>3.636650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>John Jenkins.</td>\n",
       "      <td>372</td>\n",
       "      <td>3.661503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>A new engineering building, Stinson-Remick Hal...</td>\n",
       "      <td>221</td>\n",
       "      <td>3.663944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>He soon erected additional buildings, includin...</td>\n",
       "      <td>281</td>\n",
       "      <td>3.706028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>O'Shaughnessy, at the time the largest ever ma...</td>\n",
       "      <td>175</td>\n",
       "      <td>3.719050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>With each new president, new academic programs...</td>\n",
       "      <td>285</td>\n",
       "      <td>3.725277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Jenkins took over the position from Malloy on ...</td>\n",
       "      <td>195</td>\n",
       "      <td>3.727485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>This program has been recognized previously, b...</td>\n",
       "      <td>33</td>\n",
       "      <td>3.737364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Lobund was the first research organization to ...</td>\n",
       "      <td>87</td>\n",
       "      <td>3.740897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Sentence_Index  \\\n",
       "40                                program also exists.              40   \n",
       "59   1,400 of the 3,577 (39.1%) were admitted under...              59   \n",
       "372                                      John Jenkins.             372   \n",
       "221  A new engineering building, Stinson-Remick Hal...             221   \n",
       "281  He soon erected additional buildings, includin...             281   \n",
       "175  O'Shaughnessy, at the time the largest ever ma...             175   \n",
       "285  With each new president, new academic programs...             285   \n",
       "195  Jenkins took over the position from Malloy on ...             195   \n",
       "33   This program has been recognized previously, b...              33   \n",
       "87   Lobund was the first research organization to ...              87   \n",
       "\n",
       "     WMD_Score  \n",
       "40    3.593895  \n",
       "59    3.636650  \n",
       "372   3.661503  \n",
       "221   3.663944  \n",
       "281   3.706028  \n",
       "175   3.719050  \n",
       "285   3.725277  \n",
       "195   3.727485  \n",
       "33    3.737364  \n",
       "87    3.740897  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = paragraph2(query, document)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paragraph2(query, document):\n",
    "    sent1 = [word for word in word_tokenize(query) if word not in stop_words]\n",
    "    tag = nltk.pos_tag(sent1)\n",
    "    words = []\n",
    "    for each_tag in tag:\n",
    "        if each_tag[1] == 'NN' or each_tag[1] == 'NNP' or each_tag[1] == 'NNS' or each_tag[1] == 'VBD' or each_tag[1] == 'VB':\n",
    "            words.append(each_tag[0])\n",
    "    sent1 = words\n",
    "    index = 0\n",
    "    sentences = sent_tokenize(document)\n",
    "    list_distances, list_sentence_index = [], []\n",
    "    for each_sentence in sentences:\n",
    "        sent2 = [word for word in word_tokenize(each_sentence) if word not in stop_words]\n",
    "        similarity_distance = WMD_model.wmdistance(sent1, sent2)\n",
    "        list_distances.append(similarity_distance)\n",
    "        list_sentence_index.append(index)\n",
    "        index+=1\n",
    "    WMD_Dataframe = pd.DataFrame({'Sentence': sentences, 'Sentence_Index': list_sentence_index, 'WMD_Score': list_distances}).sort_values(by=['WMD_Score'],ascending=True) \n",
    "    Top8_sentences = ' '.join([sent for sent in WMD_Dataframe[0:8].Sentence])\n",
    "   \n",
    "    return WMD_Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3: USing Named Entity Recognition, Search and then WMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'WP'), ('is', 'VBZ'), ('Grotto', 'NNP'), ('at', 'IN'), ('Norte', 'NNP'), ('Dame', 'NNP'), ('?', '.')]\n",
      "\n",
      " ****** ['Grotto', 'Norte', 'Dame'] \n",
      " ***** \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>WMD_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>The \"Notre Dame Victory March\" is the fight so...</td>\n",
       "      <td>64</td>\n",
       "      <td>3.406189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Notre Dame alumni work in various fields.</td>\n",
       "      <td>70</td>\n",
       "      <td>3.525966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Kelly's record in midway through his sixth sea...</td>\n",
       "      <td>60</td>\n",
       "      <td>3.550963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Notre Dame teams are known as the Fighting Irish.</td>\n",
       "      <td>48</td>\n",
       "      <td>3.583133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Later that day, the trumpet section will play ...</td>\n",
       "      <td>62</td>\n",
       "      <td>3.622741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>It was written by two brothers who were Notre ...</td>\n",
       "      <td>65</td>\n",
       "      <td>3.671605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Since 2005, Notre Dame has been led by John I....</td>\n",
       "      <td>33</td>\n",
       "      <td>3.688666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Holy Cross Father John Francis O'Hara was elec...</td>\n",
       "      <td>28</td>\n",
       "      <td>3.700507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The success of its football team made Notre Da...</td>\n",
       "      <td>24</td>\n",
       "      <td>3.723258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>What though the odds be great or small, old No...</td>\n",
       "      <td>67</td>\n",
       "      <td>3.726108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence  Sentence_Index  \\\n",
       "64  The \"Notre Dame Victory March\" is the fight so...              64   \n",
       "70          Notre Dame alumni work in various fields.              70   \n",
       "60  Kelly's record in midway through his sixth sea...              60   \n",
       "48  Notre Dame teams are known as the Fighting Irish.              48   \n",
       "62  Later that day, the trumpet section will play ...              62   \n",
       "65  It was written by two brothers who were Notre ...              65   \n",
       "33  Since 2005, Notre Dame has been led by John I....              33   \n",
       "28  Holy Cross Father John Francis O'Hara was elec...              28   \n",
       "24  The success of its football team made Notre Da...              24   \n",
       "67  What though the odds be great or small, old No...              67   \n",
       "\n",
       "    WMD_Score  \n",
       "64   3.406189  \n",
       "70   3.525966  \n",
       "60   3.550963  \n",
       "48   3.583133  \n",
       "62   3.622741  \n",
       "65   3.671605  \n",
       "33   3.688666  \n",
       "28   3.700507  \n",
       "24   3.723258  \n",
       "67   3.726108  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph3(query, document).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def paragraph3(query, document):\n",
    "    index = 0\n",
    "    \n",
    "    tag = nltk.pos_tag(word_tokenize(query))\n",
    "    print(tag)\n",
    "    words = []\n",
    "    for t in tag:\n",
    "        if t[1] == 'NN' or t[1] == 'NNP' or t[1] == 'NNS':\n",
    "            words.append(t[0])\n",
    "    sent1 = words\n",
    "    print(\"\\n ******\", sent1, \"\\n ***** \\n\")\n",
    "\n",
    "    sentences = sent_tokenize(document)\n",
    "    list_distances, list_sentence_index, list_sentences = [], [], []\n",
    "    \n",
    "    for each_sentence in sentences:\n",
    "        if not set(sent1).isdisjoint(each_sentence.split()):\n",
    "            sent2 = [word for word in word_tokenize(each_sentence) if word not in stop_words]\n",
    "            similarity_distance = WMD_model.wmdistance(sent1, sent2)\n",
    "            list_sentences.append(each_sentence)\n",
    "            list_distances.append(similarity_distance)\n",
    "            list_sentence_index.append(index)\n",
    "            index+=1\n",
    "    WMD_Dataframe = pd.DataFrame({'Sentence': list_sentences, 'Sentence_Index': list_sentence_index, 'WMD_Score': list_distances}).sort_values(by=['WMD_Score'],ascending=True) \n",
    "    Top8_sentences = ' '.join([sent for sent in WMD_Dataframe[0:8].Sentence])\n",
    "   \n",
    "    return WMD_Dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
